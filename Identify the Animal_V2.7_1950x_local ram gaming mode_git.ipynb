{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torchvision import datasets, transforms, models\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os, random\n",
    "from collections import OrderedDict\n",
    "import matplotlib.image as mpimg\n",
    "from torch.utils.data.dataset import Dataset  \n",
    "from torchvision import transforms  \n",
    "import pandas as pd  \n",
    "import csv\n",
    "import torch.optim.lr_scheduler\n",
    "\n",
    "\n",
    "def find_classes(dataframe):\n",
    "    classes = list(set(dataframe.iloc[:,1].values))\n",
    "    classes.sort() \n",
    "    class_to_idx={classes[i]: i for i in range(len(classes))}\n",
    "    return classes, class_to_idx    \n",
    "    \n",
    "class AnimalDataset(Dataset):\n",
    "    def __init__(self, csv_file, data_dir, transform=None):\n",
    "        self.csv_mapping = pd.read_csv(csv_file)\n",
    "        \n",
    "        self.root_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.classes, self.class_to_idx = find_classes(self.csv_mapping)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.csv_mapping)        \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.csv_mapping.iloc[idx, 0])\n",
    "        image = Image.open(img_name) \n",
    "        image = image.convert(\"RGB\")\n",
    "        label = self.class_to_idx[self.csv_mapping.iloc[idx, 1]]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return (image, label)        \n",
    "        \n",
    "    def output_layer(self):\n",
    "        return len(self.classes)\n",
    "            \n",
    "    \n",
    "    def get_class_to_idx(self):\n",
    "        return self.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([transforms.RandomRotation(20),\n",
    "                                       transforms.RandomResizedCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                            [0.229, 0.224, 0.225])])\n",
    "\n",
    "\n",
    "train_data= AnimalDataset('F:/Project/HackerEarth/Identify the Animal/meta-data/train.csv',\n",
    "                          'F:/Project/HackerEarth/Identify the Animal/train', transform = train_transforms)\n",
    "                                           \n",
    "                          \n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=64,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/32..  Training Loss: 2.619.. \n",
      "Epoch: 1/32..  Training Loss: 1.126.. \n",
      "Epoch: 1/32..  Training Loss: 0.846.. \n",
      "Epoch: 1/32..  Training Loss: 0.781.. \n",
      "Epoch: 1/32..  Training Loss: 0.669.. \n",
      "Epoch: 2/32..  Training Loss: 0.554.. \n",
      "Epoch: 2/32..  Training Loss: 0.643.. \n",
      "Epoch: 2/32..  Training Loss: 0.577.. \n",
      "Epoch: 2/32..  Training Loss: 0.570.. \n",
      "Epoch: 2/32..  Training Loss: 0.602.. \n",
      "Epoch: 3/32..  Training Loss: 0.473.. \n",
      "Epoch: 3/32..  Training Loss: 0.539.. \n",
      "Epoch: 3/32..  Training Loss: 0.533.. \n",
      "Epoch: 3/32..  Training Loss: 0.541.. \n",
      "Epoch: 3/32..  Training Loss: 0.549.. \n",
      "Epoch: 4/32..  Training Loss: 0.342.. \n",
      "Epoch: 4/32..  Training Loss: 0.511.. \n",
      "Epoch: 4/32..  Training Loss: 0.500.. \n",
      "Epoch: 4/32..  Training Loss: 0.479.. \n",
      "Epoch: 4/32..  Training Loss: 0.463.. \n",
      "Epoch: 5/32..  Training Loss: 0.260.. \n",
      "Epoch: 5/32..  Training Loss: 0.478.. \n",
      "Epoch: 5/32..  Training Loss: 0.429.. \n",
      "Epoch: 5/32..  Training Loss: 0.476.. \n",
      "Epoch: 5/32..  Training Loss: 0.465.. \n",
      "Epoch: 6/32..  Training Loss: 0.205.. \n",
      "Epoch: 6/32..  Training Loss: 0.418.. \n",
      "Epoch: 6/32..  Training Loss: 0.452.. \n",
      "Epoch: 6/32..  Training Loss: 0.442.. \n",
      "Epoch: 6/32..  Training Loss: 0.415.. \n",
      "Epoch: 7/32..  Training Loss: 0.160.. \n",
      "Epoch: 7/32..  Training Loss: 0.414.. \n",
      "Epoch: 7/32..  Training Loss: 0.423.. \n",
      "Epoch: 7/32..  Training Loss: 0.454.. \n",
      "Epoch: 7/32..  Training Loss: 0.431.. \n",
      "Epoch: 8/32..  Training Loss: 0.139.. \n",
      "Epoch: 8/32..  Training Loss: 0.411.. \n",
      "Epoch: 8/32..  Training Loss: 0.412.. \n",
      "Epoch: 8/32..  Training Loss: 0.417.. \n",
      "Epoch: 8/32..  Training Loss: 0.450.. \n",
      "Epoch: 9/32..  Training Loss: 0.087.. \n",
      "Epoch: 9/32..  Training Loss: 0.385.. \n",
      "Epoch: 9/32..  Training Loss: 0.438.. \n",
      "Epoch: 9/32..  Training Loss: 0.425.. \n",
      "Epoch: 9/32..  Training Loss: 0.400.. \n",
      "Epoch: 10/32..  Training Loss: 0.036.. \n",
      "Epoch: 10/32..  Training Loss: 0.355.. \n",
      "Epoch: 10/32..  Training Loss: 0.403.. \n",
      "Epoch: 10/32..  Training Loss: 0.408.. \n",
      "Epoch: 10/32..  Training Loss: 0.374.. \n",
      "Epoch: 10/32..  Training Loss: 0.361.. \n",
      "Epoch: 11/32..  Training Loss: 0.416.. \n",
      "Epoch: 11/32..  Training Loss: 0.366.. \n",
      "Epoch: 11/32..  Training Loss: 0.379.. \n",
      "Epoch: 11/32..  Training Loss: 0.379.. \n",
      "Epoch: 11/32..  Training Loss: 0.396.. \n",
      "Epoch: 12/32..  Training Loss: 0.315.. \n",
      "Epoch: 12/32..  Training Loss: 0.359.. \n",
      "Epoch: 12/32..  Training Loss: 0.366.. \n",
      "Epoch: 12/32..  Training Loss: 0.397.. \n",
      "Epoch: 12/32..  Training Loss: 0.363.. \n",
      "Epoch: 13/32..  Training Loss: 0.274.. \n",
      "Epoch: 13/32..  Training Loss: 0.326.. \n",
      "Epoch: 13/32..  Training Loss: 0.357.. \n",
      "Epoch: 13/32..  Training Loss: 0.353.. \n",
      "Epoch: 13/32..  Training Loss: 0.372.. \n",
      "Epoch: 14/32..  Training Loss: 0.236.. \n",
      "Epoch: 14/32..  Training Loss: 0.306.. \n",
      "Epoch: 14/32..  Training Loss: 0.334.. \n",
      "Epoch: 14/32..  Training Loss: 0.328.. \n",
      "Epoch: 14/32..  Training Loss: 0.302.. \n",
      "Epoch: 15/32..  Training Loss: 0.193.. \n",
      "Epoch: 15/32..  Training Loss: 0.302.. \n",
      "Epoch: 15/32..  Training Loss: 0.285.. \n",
      "Epoch: 15/32..  Training Loss: 0.300.. \n",
      "Epoch: 15/32..  Training Loss: 0.309.. \n",
      "Epoch: 16/32..  Training Loss: 0.148.. \n",
      "Epoch: 16/32..  Training Loss: 0.317.. \n",
      "Epoch: 16/32..  Training Loss: 0.297.. \n",
      "Epoch: 16/32..  Training Loss: 0.300.. \n",
      "Epoch: 16/32..  Training Loss: 0.300.. \n",
      "Epoch: 17/32..  Training Loss: 0.126.. \n",
      "Epoch: 17/32..  Training Loss: 0.310.. \n",
      "Epoch: 17/32..  Training Loss: 0.309.. \n",
      "Epoch: 17/32..  Training Loss: 0.302.. \n",
      "Epoch: 17/32..  Training Loss: 0.313.. \n",
      "Epoch: 18/32..  Training Loss: 0.081.. \n",
      "Epoch: 18/32..  Training Loss: 0.303.. \n",
      "Epoch: 18/32..  Training Loss: 0.299.. \n",
      "Epoch: 18/32..  Training Loss: 0.277.. \n",
      "Epoch: 18/32..  Training Loss: 0.322.. \n",
      "Epoch: 19/32..  Training Loss: 0.053.. \n",
      "Epoch: 19/32..  Training Loss: 0.308.. \n",
      "Epoch: 19/32..  Training Loss: 0.323.. \n",
      "Epoch: 19/32..  Training Loss: 0.285.. \n",
      "Epoch: 19/32..  Training Loss: 0.304.. \n",
      "Epoch: 20/32..  Training Loss: 0.028.. \n",
      "Epoch: 20/32..  Training Loss: 0.305.. \n",
      "Epoch: 20/32..  Training Loss: 0.286.. \n",
      "Epoch: 20/32..  Training Loss: 0.277.. \n",
      "Epoch: 20/32..  Training Loss: 0.291.. \n",
      "Epoch: 20/32..  Training Loss: 0.301.. \n",
      "Epoch: 21/32..  Training Loss: 0.292.. \n",
      "Epoch: 21/32..  Training Loss: 0.288.. \n",
      "Epoch: 21/32..  Training Loss: 0.288.. \n",
      "Epoch: 21/32..  Training Loss: 0.310.. \n",
      "Epoch: 21/32..  Training Loss: 0.271.. \n",
      "Epoch: 22/32..  Training Loss: 0.268.. \n",
      "Epoch: 22/32..  Training Loss: 0.305.. \n",
      "Epoch: 22/32..  Training Loss: 0.277.. \n",
      "Epoch: 22/32..  Training Loss: 0.278.. \n",
      "Epoch: 22/32..  Training Loss: 0.298.. \n",
      "Epoch: 23/32..  Training Loss: 0.215.. \n",
      "Epoch: 23/32..  Training Loss: 0.267.. \n",
      "Epoch: 23/32..  Training Loss: 0.270.. \n",
      "Epoch: 23/32..  Training Loss: 0.288.. \n",
      "Epoch: 23/32..  Training Loss: 0.274.. \n",
      "Epoch: 24/32..  Training Loss: 0.193.. \n",
      "Epoch: 24/32..  Training Loss: 0.310.. \n",
      "Epoch: 24/32..  Training Loss: 0.299.. \n",
      "Epoch: 24/32..  Training Loss: 0.283.. \n",
      "Epoch: 24/32..  Training Loss: 0.295.. \n",
      "Epoch: 25/32..  Training Loss: 0.172.. \n",
      "Epoch: 25/32..  Training Loss: 0.295.. \n",
      "Epoch: 25/32..  Training Loss: 0.262.. \n",
      "Epoch: 25/32..  Training Loss: 0.268.. \n",
      "Epoch: 25/32..  Training Loss: 0.291.. \n",
      "Epoch: 26/32..  Training Loss: 0.134.. \n",
      "Epoch: 26/32..  Training Loss: 0.292.. \n",
      "Epoch: 26/32..  Training Loss: 0.293.. \n",
      "Epoch: 26/32..  Training Loss: 0.288.. \n",
      "Epoch: 26/32..  Training Loss: 0.273.. \n",
      "Epoch: 27/32..  Training Loss: 0.117.. \n",
      "Epoch: 27/32..  Training Loss: 0.291.. \n",
      "Epoch: 27/32..  Training Loss: 0.280.. \n",
      "Epoch: 27/32..  Training Loss: 0.263.. \n",
      "Epoch: 27/32..  Training Loss: 0.310.. \n",
      "Epoch: 28/32..  Training Loss: 0.087.. \n",
      "Epoch: 28/32..  Training Loss: 0.285.. \n",
      "Epoch: 28/32..  Training Loss: 0.325.. \n",
      "Epoch: 28/32..  Training Loss: 0.274.. \n",
      "Epoch: 28/32..  Training Loss: 0.289.. \n",
      "Epoch: 29/32..  Training Loss: 0.051.. \n",
      "Epoch: 29/32..  Training Loss: 0.279.. \n",
      "Epoch: 29/32..  Training Loss: 0.284.. \n",
      "Epoch: 29/32..  Training Loss: 0.304.. \n",
      "Epoch: 29/32..  Training Loss: 0.277.. \n",
      "Epoch: 30/32..  Training Loss: 0.019.. \n",
      "Epoch: 30/32..  Training Loss: 0.298.. \n",
      "Epoch: 30/32..  Training Loss: 0.284.. \n",
      "Epoch: 30/32..  Training Loss: 0.290.. \n",
      "Epoch: 30/32..  Training Loss: 0.277.. \n",
      "Epoch: 30/32..  Training Loss: 0.277.. \n",
      "Epoch: 31/32..  Training Loss: 0.265.. \n",
      "Epoch: 31/32..  Training Loss: 0.275.. \n",
      "Epoch: 31/32..  Training Loss: 0.268.. \n",
      "Epoch: 31/32..  Training Loss: 0.295.. \n",
      "Epoch: 31/32..  Training Loss: 0.285.. \n",
      "Epoch: 32/32..  Training Loss: 0.261.. \n",
      "Epoch: 32/32..  Training Loss: 0.263.. \n",
      "Epoch: 32/32..  Training Loss: 0.296.. \n",
      "Epoch: 32/32..  Training Loss: 0.263.. \n",
      "Epoch: 32/32..  Training Loss: 0.246.. \n",
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace)\n",
      "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (17): ReLU(inplace)\n",
      "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace)\n",
      "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (24): ReLU(inplace)\n",
      "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (26): ReLU(inplace)\n",
      "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): ReLU(inplace)\n",
      "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (33): ReLU(inplace)\n",
      "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (35): ReLU(inplace)\n",
      "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (fc1): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (relu): ReLU()\n",
      "    (fc2): Linear(in_features=4096, out_features=2046, bias=True)\n",
      "    (relu2): ReLU()\n",
      "    (fc3): Linear(in_features=2046, out_features=1024, bias=True)\n",
      "    (relu3): ReLU()\n",
      "    (fc4): Linear(in_features=1024, out_features=400, bias=True)\n",
      "    (relu4): ReLU()\n",
      "    (fc5): Linear(in_features=400, out_features=30, bias=True)\n",
      "    (output): LogSoftmax()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model=models.vgg19(pretrained=True)\n",
    "input_size = model.classifier[0].in_features\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad=False\n",
    "\n",
    "    \n",
    "outp= train_data.output_layer()\n",
    "from collections import OrderedDict\n",
    "classifier = nn.Sequential(OrderedDict([\n",
    "                          ('fc1', nn.Linear(input_size,4096)), #224*224=50176\n",
    "                          ('relu', nn.ReLU()),\n",
    "                         # ('dropout',nn.Dropout(0.2)),\n",
    "                          ('fc2',nn.Linear(4096,2046)),\n",
    "                          ('relu2', nn.ReLU()),\n",
    "                         # ('dropout2',nn.Dropout(0.2)),\n",
    "                          ('fc3',nn.Linear(2046,1024)),  \n",
    "                          ('relu3', nn.ReLU()), \n",
    "                         # ('dropout',nn.Dropout(0.2)),\n",
    "                          ('fc4',nn.Linear(1024,400)),  \n",
    "                          ('relu4', nn.ReLU()), \n",
    "                        #  ('dropout4',nn.Dropout(0.2)),\n",
    "                          ('fc5', nn.Linear(400,outp)),\n",
    "                          ('output', nn.LogSoftmax(dim=1))\n",
    "                          ]))\n",
    "\n",
    "model.classifier=classifier\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=0.00005)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "epochs=32\n",
    "print_every =40\n",
    "steps=0\n",
    "\n",
    "exp_lr_scheduler=optim.lr_scheduler.MultiStepLR(optimizer, milestones=[13,22,29], gamma=0.1)\n",
    "for e in range(epochs):\n",
    "    model.train()  \n",
    "    running_loss=0\n",
    "    exp_lr_scheduler.step()\n",
    "    for images, labels in iter(trainloader):\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        images,labels = images.to(device),labels.to(device)\n",
    "    \n",
    "        steps+=1\n",
    "        images.resize_(images.shape[0],3,224,224)\n",
    "        optimizer.zero_grad()\n",
    "        output=model.forward(images)\n",
    "        loss=criterion(output,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss+=loss.item()\n",
    "        \n",
    "        if steps%print_every==0:\n",
    "            model.eval()\n",
    "            \n",
    "            print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                  \"Training Loss: {:.3f}.. \".format(running_loss/print_every))\n",
    "            \n",
    "            running_loss = 0\n",
    "            model.train()\n",
    "            \n",
    "            \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.class_to_idx = train_data.class_to_idx\n",
    "\n",
    "checkpoint = {'in_features': 25088,\n",
    "              'out_features': outp,\n",
    "              'epoch': 3,\n",
    "              'optimizer' : optimizer.state_dict(),\n",
    "              'state_dict': model.state_dict(),\n",
    "              'class_to_idx': train_data.class_to_idx,\n",
    "              'classifier': classifier.state_dict(),\n",
    "              'lr':0.001}\n",
    "\n",
    "torch.save(checkpoint, 'F:/Project/HackerEarth/Identify the Animal/checkpoint_2.7.pth')       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "\n",
    "    pil_image= Image.open(image)\n",
    "\n",
    "    size=256,256\n",
    "    pil_image.thumbnail(size)\n",
    "    \n",
    "    \n",
    "    width,height = 256,256\n",
    "    left = (width - 224)/2\n",
    "    top = (height - 224)/2\n",
    "    right = (width + 224)/2   \n",
    "    bottom = (height + 224)/2    \n",
    "    np_image = np.array(pil_image.crop((left, top, right, bottom))) \n",
    "\n",
    "\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "    np_image=(np_image/255-mean)/std  #/255 is necessary\n",
    "    np_image= np.transpose(np_image, (2, 0, 1))\n",
    "    \n",
    "    return np_image\n",
    "\n",
    "def predict(image_path, model):\n",
    "\n",
    "    \n",
    "    np_array = process_image(image_path)\n",
    "    tensor_image = torch.from_numpy(np_array).double()\n",
    "    \n",
    "    \n",
    "    var_inputs = Variable(tensor_image)\n",
    "    \n",
    "    var_inputs = var_inputs.unsqueeze(0)\n",
    "    var_inputs=var_inputs.float().to(device)\n",
    "\n",
    "    output = model.forward(var_inputs)  \n",
    "    ps=torch.exp(output)\n",
    "    tn_probs = ps.cpu()\n",
    "    probs=tn_probs.detach().numpy()\n",
    "    probs=probs.flatten().tolist()  \n",
    "\n",
    "    return probs \n",
    "\n",
    "\n",
    "probs = predict('F:/Project/HackerEarth/Identify the Animal/test/Img-1.jpg',model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_header=class_names.copy()\n",
    "class_header.insert(0,'image_id')\n",
    "\n",
    "import csv\n",
    "test_imgs_name= list(pd.read_csv('F:/Project/HackerEarth/Identify the Animal/test.csv').iloc[:,0])\n",
    "with open('F:/Project/HackerEarth/Identify the Animal/predictionv2.7.csv', 'w') as f:\n",
    "    writer = csv.writer(f,lineterminator = '\\n')\n",
    "    writer.writerow(class_header)\n",
    "    for test_img in test_imgs_name:\n",
    "        probs = predict(('F:/Project/HackerEarth/Identify the Animal/test/'+ test_img),model)\n",
    "        probs.insert(0,test_img)\n",
    "        writer.writerow(probs)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11835.853644132614\n"
     ]
    }
   ],
   "source": [
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Score\n",
    "#0.86119"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
